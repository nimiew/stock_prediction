{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Crytocurrency Prices with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at one of the datasets. There are 3 more files for BTC, BCH and ETH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1528968660</td>\n",
       "      <td>96.580002</td>\n",
       "      <td>96.589996</td>\n",
       "      <td>96.589996</td>\n",
       "      <td>96.580002</td>\n",
       "      <td>9.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1528968720</td>\n",
       "      <td>96.449997</td>\n",
       "      <td>96.669998</td>\n",
       "      <td>96.589996</td>\n",
       "      <td>96.660004</td>\n",
       "      <td>314.387024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1528968780</td>\n",
       "      <td>96.470001</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>77.129799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1528968840</td>\n",
       "      <td>96.449997</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>96.570000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>7.216067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1528968900</td>\n",
       "      <td>96.279999</td>\n",
       "      <td>96.540001</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>96.389999</td>\n",
       "      <td>524.539978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time        low       high       open      close      volume\n",
       "0  1528968660  96.580002  96.589996  96.589996  96.580002    9.647200\n",
       "1  1528968720  96.449997  96.669998  96.589996  96.660004  314.387024\n",
       "2  1528968780  96.470001  96.570000  96.570000  96.570000   77.129799\n",
       "3  1528968840  96.449997  96.570000  96.570000  96.500000    7.216067\n",
       "4  1528968900  96.279999  96.540001  96.500000  96.389999  524.539978"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"crypto_data/LTC-USD.csv\", names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolating close and volume data and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]\n",
    "\n",
    "for ratio in ratios:\n",
    "    dataset = f'crypto_data/{ratio}.csv'\n",
    "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "    \n",
    "    # Each dataset have its unique col name for close and volume\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True)\n",
    "\n",
    "    df.set_index(\"time\", inplace=True) # so we can join on time\n",
    "    df = df.loc[:, [f\"{ratio}_close\", f\"{ratio}_volume\"]] # only keep price and volumne cols\n",
    "\n",
    "    if len(main_df)==0: # account for first dataframe\n",
    "        main_df = df\n",
    "    else:\n",
    "        main_df = main_df.join(df)\n",
    "\n",
    "main_df.fillna(method=\"ffill\", inplace=True)  # if there are gaps in data, use previously known values\n",
    "main_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is how our cleaned data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
      "1528968960    6480.000000        1.490900      96.519997       16.991997   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \n",
      "time                                                                      \n",
      "1528968720     870.859985       26.856577      486.01001       26.019083  \n",
      "1528968780     870.099976        1.124300      486.00000        8.449400  \n",
      "1528968840     870.789978        1.749862      485.75000       26.994646  \n",
      "1528968900     870.000000        1.680500      486.00000       77.355759  \n",
      "1528968960     869.989990        1.669014      486.00000        7.503300  \n"
     ]
    }
   ],
   "source": [
    "print(main_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whats our target?\n",
    "We will use a sequence length of 60, amd a future prediction out of 3.\n",
    "We will perform binary classification, which means if the price goes up in 3 minutes, then we buy and if it goes down in 3 minutes, then we do not buy/sell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60  # how long of a preceeding sequence to collect for RNN\n",
    "FUTURE_PERIOD_PREDICT = 3  # how far into the future are we trying to predict?\n",
    "RATIO_TO_PREDICT = \"LTC-USD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column for 3rd future column\n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "# Apply a mapping function to create our target column\n",
    "classify = lambda current, future: 1 if float(future) > float(current) else 0\n",
    "main_df['target'] = main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is what we have processed so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close  BTC-USD_volume  LTC-USD_close  LTC-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "1528968900    6479.979980        0.753000      96.389999      524.539978   \n",
      "1528968960    6480.000000        1.490900      96.519997       16.991997   \n",
      "\n",
      "            BCH-USD_close  BCH-USD_volume  ETH-USD_close  ETH-USD_volume  \\\n",
      "time                                                                       \n",
      "1528968720     870.859985       26.856577      486.01001       26.019083   \n",
      "1528968780     870.099976        1.124300      486.00000        8.449400   \n",
      "1528968840     870.789978        1.749862      485.75000       26.994646   \n",
      "1528968900     870.000000        1.680500      486.00000       77.355759   \n",
      "1528968960     869.989990        1.669014      486.00000        7.503300   \n",
      "\n",
      "               future  target  \n",
      "time                           \n",
      "1528968720  96.389999       0  \n",
      "1528968780  96.519997       0  \n",
      "1528968840  96.440002       0  \n",
      "1528968900  96.470001       1  \n",
      "1528968960  96.400002       0  \n"
     ]
    }
   ],
   "source": [
    "print(main_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a closer look at LTC-USD_close, future, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future  target\n",
      "time                                        \n",
      "1528968720      96.660004  96.389999       0\n",
      "1528968780      96.570000  96.519997       0\n",
      "1528968840      96.500000  96.440002       0\n",
      "1528968900      96.389999  96.470001       1\n",
      "1528968960      96.519997  96.400002       0\n",
      "1528969020      96.440002  96.400002       0\n",
      "1528969080      96.470001  96.400002       0\n",
      "1528969140      96.400002  96.400002       0\n",
      "1528969200      96.400002  96.400002       0\n",
      "1528969260      96.400002  96.449997       1\n"
     ]
    }
   ],
   "source": [
    "print(main_df.loc[:, [\"LTC-USD_close\", \"future\", \"target\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining training and validation sets\n",
    "For time-series prediction, especially stock prices, we need to be careful in how we build our test set.\n",
    "\n",
    "We will use the last 5% as validation set, first 95% as training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(main_df.index.values)\n",
    "last_5pct = times[-int(0.05*len(times))] # get time at 95 percentile\n",
    "validation_main_df = main_df[(main_df.index >= last_5pct)]  # make the validation data contain time > 95 percentile\n",
    "main_df = main_df[(main_df.index < last_5pct)]  # maindf contain time < 95 percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df = df.drop(\"future\", 1)  # discard this, only needed for calculating target\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != \"target\":\n",
    "            df[col] = df[col].pct_change() # interested in relative movement\n",
    "            df.dropna(inplace=True)\n",
    "            df[col] = preprocessing.scale(df[col].values) # values normalized to between 0 and 1\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    sequential_data = []  # list of sequences\n",
    "    prev_days = deque(maxlen=SEQ_LEN)  # Each individual sequence, deque ensure len < SEQ_LEN\n",
    "\n",
    "    for i in df.values:  # df.values convert to list of lists\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # deque is full and we have a sequence\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "\n",
    "    random.shuffle(sequential_data)  # remove any semblance of bias\n",
    "    \n",
    "    # We need to ensure there is no class imbalance as that can skew our results\n",
    "    buys = [[seq, target] for seq, target in sequential_data if target==0]\n",
    "    sells = [[seq, target] for seq, target in sequential_data if target!=0]\n",
    "    \n",
    "    # Discard excess sequences if there are too many buy/sell sequences\n",
    "    lower = min(len(buys), len(sells))\n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "\n",
    "    sequential_data = buys+sells\n",
    "    random.shuffle(sequential_data)  # so we don't get a chuck of buy sequences then a chuck of sell sequences\n",
    "    \n",
    "    return np.array([seq for seq, target in sequential_data]), [target for seq, target in sequential_data]\n",
    "\n",
    "train_x, train_y = preprocess_df(main_df)\n",
    "validation_x, validation_y = preprocess_df(validation_main_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train seqs: 77922, num validation seqs: 3860\n",
      "\n",
      "train:\n",
      "dont buys: 38961, buys: 38961\n",
      "\n",
      "validation:\n",
      "dont buys: 1930, buys: 1930\n"
     ]
    }
   ],
   "source": [
    "print(f\"num train seqs: {len(train_x)}, num validation seqs: {len(validation_x)}\")\n",
    "print(\"\\ntrain:\")\n",
    "print(f\"dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
    "print(\"\\nvalidation:\")\n",
    "print(f\"dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\" # model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 21:03:18.205071  3860 deprecation.py:506] From C:\\Users\\AJL\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(CuDNNLSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(CuDNNLSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 77922 samples, validate on 3860 samples\n",
      "Epoch 1/10\n",
      "77922/77922 [==============================] - 21s 274us/sample - loss: 0.7229 - acc: 0.5207 - val_loss: 0.6926 - val_acc: 0.5039\n",
      "Epoch 2/10\n",
      "77922/77922 [==============================] - 19s 249us/sample - loss: 0.6929 - acc: 0.5145 - val_loss: 0.6931 - val_acc: 0.5197\n",
      "Epoch 3/10\n",
      "77922/77922 [==============================] - 19s 249us/sample - loss: 0.6927 - acc: 0.5147 - val_loss: 0.6855 - val_acc: 0.5585\n",
      "Epoch 4/10\n",
      "77922/77922 [==============================] - 19s 248us/sample - loss: 0.6892 - acc: 0.5374 - val_loss: 0.6856 - val_acc: 0.5531\n",
      "Epoch 5/10\n",
      "77922/77922 [==============================] - 20s 258us/sample - loss: 0.6858 - acc: 0.5520 - val_loss: 0.6832 - val_acc: 0.5614\n",
      "Epoch 6/10\n",
      "77922/77922 [==============================] - 20s 252us/sample - loss: 0.6841 - acc: 0.5576 - val_loss: 0.6845 - val_acc: 0.5614\n",
      "Epoch 7/10\n",
      "77922/77922 [==============================] - 20s 252us/sample - loss: 0.6823 - acc: 0.5614 - val_loss: 0.6786 - val_acc: 0.5720\n",
      "Epoch 8/10\n",
      "77922/77922 [==============================] - 20s 259us/sample - loss: 0.6809 - acc: 0.5653 - val_loss: 0.6728 - val_acc: 0.5777\n",
      "Epoch 9/10\n",
      "77922/77922 [==============================] - 21s 272us/sample - loss: 0.6795 - acc: 0.5687 - val_loss: 0.6725 - val_acc: 0.5801\n",
      "Epoch 10/10\n",
      "77922/77922 [==============================] - 21s 273us/sample - loss: 0.6790 - acc: 0.5691 - val_loss: 0.6767 - val_acc: 0.5676\n"
     ]
    }
   ],
   "source": [
    "filepath = \"RNN_Final\"\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1,\n",
    "                                                      save_best_only=True, mode='max'))\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, validation_y),\n",
    "    callbacks=[checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6767151699164988\n",
      "Test accuracy: 0.5676166\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Valid loss:', score[0])\n",
    "print('Valid accuracy:', score[1])\n",
    "# Save model\n",
    "model.save(\"models/{}\".format(NAME))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
